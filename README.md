# Examining-Gender-Occupation-Bias-in-Krio-Translations
Krio is an English based creole spoken by Sierra Leoneans.1 One interesting thing about the
language is that it uses the gender neutral pronoun, "e," to signify the third person singular (he,
she, it) and often native speakers forgo using it entirely, allowing context to imply the correct
pronoun. For example, the sentence, "She/he/it/they/ is/are a teacher," can be translated as "E
na ticha" and "Na ticha." GPT models are a collection of large language models produced by
OpenAI that are capable of a host of tasks, including machine translation.2 Thus, for translation,
a GPT model should be able to use previous context to determine what pronoun they should to
translate the sentence and/or guess a gender neutral pronoun without context. However, research
has shown that chatGPT tends to show gender bias towards certain occupations by assigning
gendered pronouns (i.e. doctor = ’he’, nurse = ’she’) during translation of languages with gender
neutral pronouns.3 Therefore, my project investigates potential gender-occupation bias in GPT
Krio translations. This project is also personally significant as I am Sierra Leonean myself and
found the exploration of my family’s language very interesting.
