{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19049,"status":"ok","timestamp":1724209013764,"user":{"displayName":"Sydney Faux","userId":"18400187356723115182"},"user_tz":420},"id":"VfG93gifqT5-","outputId":"7be861c9-5879-46b3-995f-d3146f25554e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q streamlit"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":384,"status":"ok","timestamp":1724209111243,"user":{"displayName":"Sydney Faux","userId":"18400187356723115182"},"user_tz":420},"id":"PGqn1XGjsoCp","outputId":"9561e3d3-82f6-4a60-cf63-80cc3252745d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}],"source":["%%writefile app.py\n","\n","import streamlit as st\n","import pandas as pd\n","import math\n","import numpy as np\n","from scipy.stats import norm\n","import matplotlib.pyplot as plt\n","\n","df_35 = pd.read_csv(\"translations-3.5-turbo-processed.csv\")\n","df4 = pd.read_csv(\"translations-4-processed.csv\")\n","df_003 = pd.read_csv(\"translations-text-davinci-003-processed.csv\")\n","\n","\n","def calculate_bias(df, option):\n","  selected_df = df[df[\"demographic\"].str.contains(option)]\n","  num=0\n","  denom = 0\n","  for i,xs in selected_df.iterrows():\n","    if (xs[2] == 1 or xs[2] == 2):\n","      num += 1\n","    if (xs[2] == 0 or xs[2] == 2):\n","      denom += 1\n","  num +=1\n","  denom+=1\n","  bias = math.log(num)-math.log(denom)\n","  st.write(option + \" bias: \" + str(bias))\n","\n","\n","def calculate_bias_return(df, option):\n","  selected_df = df[df[\"demographic\"].str.contains(option)]\n","  num=0\n","  denom = 0\n","  for i,xs in selected_df.iterrows():\n","    if (xs[2] == 1 or xs[2] == 2):\n","      num += 1\n","    if (xs[2] == 0 or xs[2] == 2):\n","      denom += 1\n","  num +=1\n","  denom+=1\n","  bias = math.log(num)-math.log(denom)\n","  return bias\n","\n","\n","def parameter_estimation(df):\n","  occupations = [\"doctor\", \"nurse\", \"teacher\", \"accountant\", \"pastor\", \"security guard\", \"bartender\", \"engineer\"]\n","  calibrations = []\n","  for occupation in occupations:\n","    calibrations.append(calculate_bias_return(df,occupation))\n","\n","  mu = np.mean(calibrations)\n","  theta_squared = 0\n","\n","  for calibration in calibrations:\n","    theta_squared += (calibration-mu)**2\n","  theta_squared = theta_squared/len(calibrations)\n","  return mu, theta_squared\n","\n","def more_likely(mu, theta_squared,mu2, theta_squared2, C):\n","  X = norm(mu,math.sqrt(theta_squared))\n","  Y = norm(mu2,math.sqrt(theta_squared2))\n","  num = X.pdf(C)\n","  denom = Y.pdf(C)\n","  return float(num/denom)\n","\n","st.header('Examining Gender Bias in Krio Translation by ChatGPT')\n","st.subheader('Calibration - Detecting Gender Bias')\n","\n","option_model = st.selectbox('Choose a model.', ('<select>','gpt 3.5', 'gpt 4', 'davinci-003'))\n","\n","if option_model != '<select>' and option_model=='gpt 3.5':\n","  option = st.selectbox('Choose an occupation.', ('<select>', \"doctor\", \"nurse\", \"teacher\", \"accountant\", \"pastor\", \"security guard\", \"bartender\", \"engineer\"))\n","\n","  if option != '<select>':\n","    calculate_bias(df_35, option)\n","\n","elif option_model=='gpt 4':\n","  option = st.selectbox('Choose a occupation.', ('<select>', \"doctor\", \"nurse\", \"teacher\", \"accountant\", \"pastor\", \"security guard\", \"bartender\", \"engineer\"))\n","\n","  if option != '<select>':\n","    calculate_bias(df4, option)\n","\n","elif option_model != '<select>' and option_model=='davinci-003':\n","  option = st.selectbox('Choose a occupation.', ('<select>', \"doctor\", \"nurse\", \"teacher\", \"accountant\", \"pastor\", \"security guard\", \"bartender\", \"engineer\"))\n","\n","  if option != '<select>':\n","    calculate_bias(df_003, option)\n","\n","st.subheader('Inference - Can We Tell Which GPT Did the Translations?')\n","option_model1 = st.selectbox('Choose a model.', ('<select>','gpt 3.5', 'gpt 4', 'davinci-003', 'davinci-002'), key=\"1\")\n","option_model2 = st.selectbox('Choose a model.', ('<select>','gpt 3.5', 'gpt 4', 'davinci-003', 'davinci-002'), key=\"2\")\n","\n","if option_model1!=\"<select>\" and option_model2!=\"<select>\":\n","  model_to_df = {'gpt 3.5' : df_35, 'gpt 4' : df4, 'davinci-003' : df_003}\n","  mu, theta_squared = parameter_estimation(model_to_df[option_model1])\n","  mu2, theta_squared2 = parameter_estimation(model_to_df[option_model2])\n","  mean_calibration = st.text_input(\"Input mean bias\")\n","  if (mean_calibration != \"\"):\n","    p = more_likely(mu,theta_squared,mu2,theta_squared2,float(mean_calibration))\n","    if (p > 1):\n","      st.write(option_model1 + \" is more likely to be the translator\")\n","    elif (p < 1):\n","      st.write(option_model2 + \" is more likely to be the translator\")\n","    else:\n","      st.write(\"no clue\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":698,"status":"ok","timestamp":1724209113176,"user":{"displayName":"Sydney Faux","userId":"18400187356723115182"},"user_tz":420},"id":"P_zWKbd_tsts","outputId":"8b7190fc-700c-45a9-95e5-898662e1b798"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h\n","up to date, audited 23 packages in 501ms\n","\n","3 packages are looking for funding\n","  run `npm fund` for details\n","\n","2 \u001b[33m\u001b[1mmoderate\u001b[22m\u001b[39m severity vulnerabilities\n","\n","To address all issues (including breaking changes), run:\n","  npm audit fix --force\n","\n","Run `npm audit` for details.\n"]}],"source":["!npm install localtunnel"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":365,"status":"ok","timestamp":1724209113540,"user":{"displayName":"Sydney Faux","userId":"18400187356723115182"},"user_tz":420},"id":"n0p65MlTt9VH","outputId":"e37b37e8-e394-4484-a97d-ebc43e249e2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["34.138.209.99\n"]}],"source":["!streamlit run app.py &>/content/logs.txt & curl ipv4.icanhazip.com"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JnUF9oIjuAED","outputId":"c8da48b6-8011-4bdc-d330-a1bab9a2e27b"},"outputs":[{"output_type":"stream","name":"stdout","text":["your url is: https://three-flies-suffer.loca.lt\n"]}],"source":["!npx localtunnel --port 8501"]},{"cell_type":"code","source":[],"metadata":{"id":"cvqWMr-QZNYt"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnn/2weq+fJ413aw7k+aNi"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}